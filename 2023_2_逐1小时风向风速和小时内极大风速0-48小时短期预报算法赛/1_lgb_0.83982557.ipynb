{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-10T13:45:53.097578Z","iopub.status.busy":"2023-03-10T13:45:53.096476Z","iopub.status.idle":"2023-03-10T13:45:53.879567Z","shell.execute_reply":"2023-03-10T13:45:53.877396Z","shell.execute_reply.started":"2023-03-10T13:45:53.097530Z"},"trusted":true},"outputs":[],"source":["import getpass\n","KAGGLE = False if getpass.getuser() == \"Kaihua\" else True\n","\n","import os, copy, zipfile, re\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import networkx as nx\n","from functools import reduce\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-10T13:45:53.887735Z","iopub.status.busy":"2023-03-10T13:45:53.887208Z","iopub.status.idle":"2023-03-10T13:45:55.077345Z","shell.execute_reply":"2023-03-10T13:45:55.075607Z","shell.execute_reply.started":"2023-03-10T13:45:53.887685Z"},"trusted":true},"outputs":[],"source":["import sys\n","if KAGGLE:\n","    sys.path.append(\"/kaggle/input/2023zhuxiaoshifengxiang\")\n","    DATA_PATH = '/kaggle/input/2023zhuxiaoshifengxiang'\n","else:\n","    sys.path.append(\"../code集合/models\")\n","    sys.path.append(\"../code集合/feature_extraction\")\n","    DATA_PATH = 'data'\n","\n","\n","SEED = 2023\n","MODEL_SAVE_PATH = 'model'\n","RESULT_SAVE_PATH = 'results'\n","if not os.path.exists(MODEL_SAVE_PATH):\n","    os.makedirs(MODEL_SAVE_PATH)\n","if not os.path.exists(RESULT_SAVE_PATH):\n","    os.makedirs(RESULT_SAVE_PATH)\n","cat_feats = []"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_data: (791616, 77)\n","test_data: (216384, 74)\n","all: (1008000, 80)\n"]},{"data":{"text/plain":["(0, 0)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_parquet(os.path.join(DATA_PATH, 'track3_train.parquet'))\n","test_data = pd.read_parquet(os.path.join(DATA_PATH, 'track3_a.parquet'))\n","\n","train_data['type'] = 'train'\n","test_data['type'] = 'test'\n","data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n","data = pd.concat([data, data['ID'].str.split('_', expand=True).rename(columns={0:'station',1:'sample',2:'time'})], axis=1)\n","\n","print(f'train_data: {train_data.shape}')\n","print(f'test_data: {test_data.shape}')\n","print(f'all: {data.shape}')\n","\n","(data['sample'].value_counts() != 672).sum(), train_data.isna().sum().sum()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["TARGET_FEATS = ['wdir_2min', 'spd_2min', 'spd_inst_max']"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# 删除有问题的目标\n","for item in TARGET_FEATS:\n","    idx = data[item] >= 199999.0\n","    data.loc[idx, item] = np.nan"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["data['station'] = data['station'].apply(lambda x: int(x.split('D')[-1]))\n","cat_feats += ['station']\n","\n","data['sample'] = data['sample'].apply(lambda x: int(x.split('Sample')[-1]))\n","data['time'] = data['time'].astype(int)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["feats: 74, ['100u', '100v', '10u', '10v', '2d', '2t', 'cape', 'capes', 'cp', 'deg0l', 'lcc', 'msl', 'skt', 'sp', 'sst', 'tcc', 'd_L1000', 'q_L1000', 'r_L1000', 't_L1000', 'u_L1000', 'v_L1000', 'w_L1000', 'd_L950', 'q_L950', 'r_L950', 't_L950', 'u_L950', 'v_L950', 'w_L950', 'd_L925', 'q_L925', 'r_L925', 't_L925', 'u_L925', 'v_L925', 'w_L925', 'd_L900', 'q_L900', 'r_L900', 't_L900', 'u_L900', 'v_L900', 'w_L900', 'd_L850', 'q_L850', 'r_L850', 't_L850', 'u_L850', 'v_L850', 'w_L850', 'd_L700', 'q_L700', 'r_L700', 't_L700', 'u_L700', 'v_L700', 'w_L700', 'd_L500', 'q_L500', 'r_L500', 't_L500', 'u_L500', 'v_L500', 'w_L500', 'd_L200', 'q_L200', 'r_L200', 't_L200', 'u_L200', 'v_L200', 'w_L200', 'station', 'time']\n","['station']\n"]}],"source":["feats = [item for item in data.columns if item not in TARGET_FEATS+['ID', 'sample', 'type']]\n","print(f'feats: {len(feats)}, {feats}')\n","print(cat_feats)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_data = data.query('type==\"train\"').reset_index(drop=True)\n","test_data = data.query('type==\"test\"').reset_index(drop=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["lgb_params = {\n","    'boosting_type': 'gbdt',\n","    'objective': 'mse', #mse mape\n","    'metric': 'rmse',\n","    # 'max_depth': 6,\n","    'num_leaves': 2 ** 6, # 2**4\n","    # 'num_leaves': 31,\n","    'min_data_in_leaf': 20,\n","#     'lambda_l1': 0.5,  \n","#     'lambda_l2': 0.5,  \n","    'feature_fraction': 0.7,  \n","    'bagging_fraction': 0.7, \n","    'bagging_freq': 5,  \n","    'learning_rate': 0.01,  \n","    'n_jobs': -1,\n","    'verbose': -1,\n","    \"device_type\": \"cpu\",\n","    'feature_fraction_seed':SEED,\n","    'bagging_seed':SEED,\n","    'seed': SEED,\n","}\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# 逐小时预报采用四舍五入保留1位小数位\n","# 24小时内最大风由保留1位小数位的逐小时平均风速求最大值\n","# 24小时内极大风由保留1位小数位的逐小时极大风速求最大值\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["task_name = \"lgb\"\n","task_params = {\"lgb\": lgb_params}[task_name]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(770742, 74) (216384, 74)\n","----------- 0\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 59.232\tvalid_1's rmse: 65.9939\n","[10000]\ttraining's rmse: 52.6263\tvalid_1's rmse: 63.5982\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 52.6263\tvalid_1's rmse: 63.5982\n","----------- 1\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 59.0363\tvalid_1's rmse: 66.3904\n","[10000]\ttraining's rmse: 52.3619\tvalid_1's rmse: 63.9672\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 52.3619\tvalid_1's rmse: 63.9672\n","----------- 2\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 59.081\tvalid_1's rmse: 66.5326\n","[10000]\ttraining's rmse: 52.4349\tvalid_1's rmse: 64.0907\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 52.4349\tvalid_1's rmse: 64.0907\n","----------- 3\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 58.9946\tvalid_1's rmse: 67.0283\n","[10000]\ttraining's rmse: 52.3004\tvalid_1's rmse: 64.6402\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 52.3004\tvalid_1's rmse: 64.6402\n","----------- 4\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 58.8965\tvalid_1's rmse: 67.5477\n","[10000]\ttraining's rmse: 52.2676\tvalid_1's rmse: 65.1389\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 52.2676\tvalid_1's rmse: 65.1389\n","(782412, 74) (216384, 74)\n","----------- 0\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.32831\tvalid_1's rmse: 1.48649\n","[10000]\ttraining's rmse: 1.16976\tvalid_1's rmse: 1.40878\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.16976\tvalid_1's rmse: 1.40878\n","----------- 1\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.325\tvalid_1's rmse: 1.49741\n","[10000]\ttraining's rmse: 1.16821\tvalid_1's rmse: 1.42196\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.16821\tvalid_1's rmse: 1.42196\n","----------- 2\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.32771\tvalid_1's rmse: 1.50133\n","[10000]\ttraining's rmse: 1.17103\tvalid_1's rmse: 1.42438\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.17103\tvalid_1's rmse: 1.42438\n","----------- 3\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.33118\tvalid_1's rmse: 1.46951\n","[10000]\ttraining's rmse: 1.1733\tvalid_1's rmse: 1.39478\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.1733\tvalid_1's rmse: 1.39478\n","----------- 4\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.32814\tvalid_1's rmse: 1.49294\n","[10000]\ttraining's rmse: 1.17089\tvalid_1's rmse: 1.41688\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.17089\tvalid_1's rmse: 1.41688\n","(782450, 74) (216384, 74)\n","----------- 0\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.55534\tvalid_1's rmse: 1.74999\n","[10000]\ttraining's rmse: 1.33409\tvalid_1's rmse: 1.64222\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.33409\tvalid_1's rmse: 1.64222\n","----------- 1\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.55093\tvalid_1's rmse: 1.76622\n","[10000]\ttraining's rmse: 1.33044\tvalid_1's rmse: 1.66025\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.33044\tvalid_1's rmse: 1.66025\n","----------- 2\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.54191\tvalid_1's rmse: 1.8306\n","[10000]\ttraining's rmse: 1.32279\tvalid_1's rmse: 1.72424\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.32279\tvalid_1's rmse: 1.72424\n","----------- 3\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.54275\tvalid_1's rmse: 1.80172\n","[10000]\ttraining's rmse: 1.32592\tvalid_1's rmse: 1.69239\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.32592\tvalid_1's rmse: 1.69239\n","----------- 4\n","Training until validation scores don't improve for 100 rounds\n","[5000]\ttraining's rmse: 1.54562\tvalid_1's rmse: 1.81591\n","[10000]\ttraining's rmse: 1.32572\tvalid_1's rmse: 1.70771\n","Did not meet early stopping. Best iteration is:\n","[10000]\ttraining's rmse: 1.32572\tvalid_1's rmse: 1.70771\n"]}],"source":["train_oof = {}\n","test_pred = {}\n","feats_importance = {}\n","\n","for item_target in TARGET_FEATS:\n","    train_y = train_data[item_target]\n","    idx = ~train_y.isna()\n","\n","    trian_id = train_data.loc[idx, 'ID'].reset_index(drop=True)\n","    train_x = train_data.loc[idx, feats].reset_index(drop=True)\n","    testA_x = test_data[feats].reset_index(drop=True)\n","    train_y = train_y.loc[idx].reset_index(drop=True)\n","    group_x = train_data.loc[idx, 'sample'].reset_index(drop=True)\n","    print(train_x.shape, testA_x.shape)\n","\n","    item_oof = np.zeros(train_x.shape[0])\n","    item_pred = np.zeros(testA_x.shape[0])\n","\n","    fold_num = 5\n","    item_importance = 0\n","    from sklearn.model_selection import GroupKFold\n","    import lightgbm as lgb\n","    kf = GroupKFold(n_splits=fold_num, )\n","    for fold, (train_idx, val_idx) in enumerate(kf.split(train_x, groups=group_x)):\n","        print('-----------', fold)\n","        train = lgb.Dataset(\n","            train_x.loc[train_idx],\n","            train_y.loc[train_idx],\n","            categorical_feature=cat_feats\n","        )\n","        val = lgb.Dataset(\n","            train_x.loc[val_idx],\n","            train_y.loc[val_idx],\n","            categorical_feature=cat_feats\n","        )\n","        model = lgb.train(task_params, train, valid_sets=[train, val], num_boost_round=10_000,\n","                            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(5_000)])\n","\n","        item_oof[val_idx] += (model.predict(train_x.loc[val_idx]))\n","        item_pred += (model.predict(testA_x))/fold_num\n","        item_importance += model.feature_importance(importance_type='gain') / fold_num\n","\n","    importance = pd.DataFrame()\n","    importance['name'] = feats\n","    importance['importance'] = item_importance\n","\n","    train_oof[item_target] = pd.DataFrame({\"ID\": trian_id, f\"{item_target}_true\": train_y, f\"{item_target}_pred\": item_oof})\n","    test_pred[item_target] = pd.DataFrame({\"ID\": test_data['ID'], f\"{item_target}\": item_pred})\n","    feats_importance[item_target] = importance"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["((782462, 7), (216384, 4))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_oof = reduce(lambda x,y: pd.merge(x,y,on='ID', how='outer'), train_oof.values())\n","test_pred = reduce(lambda x,y: pd.merge(x,y,on='ID', how='outer'), test_pred.values())\n","train_oof.shape, test_pred.shape"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["score_str = 0"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# for item_key in feats_importance:\n","#     item_importance = feats_importance[item_key]\n","#     item_importance['mean'] = item_importance[[item for item in item_importance.columns if item.startswith('fold')]].mean(1)\n","#     item_importance['std'] = item_importance[[item for item in item_importance.columns if item.startswith('fold')]].std(1)\n","#     item_importance = item_importance.sort_values(['mean', 'std'], ascending=False)\n","#     item_importance.to_csv(os.path.join(RESULT_SAVE_PATH, f'feats_importance_{item_key}_{score_str}.csv'), index=False)\n","    "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["train_oof.to_csv(os.path.join(RESULT_SAVE_PATH, f'lgb_oof_{score_str}.csv'), index=False)\n","test_pred.to_csv(os.path.join(RESULT_SAVE_PATH, f'lgb_pre_{score_str}.csv'), index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.11 ('AL')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"vscode":{"interpreter":{"hash":"82785e3617b41da40eac9dc72b5795aea1d455d121b27bd2aa7c1fc59bb3871c"}}},"nbformat":4,"nbformat_minor":4}
